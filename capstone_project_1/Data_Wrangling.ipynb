{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 1 Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to perform data wrangling steps on the Walmart Trip Type Classification datasets from Kaggle.  There are two files included: the training data and the test data.  The cleaning steps include:\n",
    "\n",
    "- loadings the files,\n",
    "- analyzing the data types of the variables,\n",
    "- and treating missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Steps\n",
    "First we perform standard steps to load the .csv files into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the working directory to be the respository containing the data\n",
    "which will be different for the user than it is for me.\n",
    "\n",
    "The original data source is:\n",
    "https://www.kaggle.com/c/walmart-recruiting-trip-type-classification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nick/Desktop/Springboard/Capstone_1/Original_Data\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/Springboard/Capstone_1/Original_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data in Python as pandas data frames\n",
    "\n",
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')\n",
    "\n",
    "# Create a list of the two data frames to be looped over later.\n",
    "dfs=[train_df,test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Data Types\n",
    "Now that the data is available, we being by observing the different features in each data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TripType', 'VisitNumber', 'Weekday', 'Upc', 'ScanCount',\n",
      "       'DepartmentDescription', 'FinelineNumber'],\n",
      "      dtype='object') \n",
      "\n",
      "Index(['VisitNumber', 'Weekday', 'Upc', 'ScanCount', 'DepartmentDescription',\n",
      "       'FinelineNumber'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect column names.\n",
    "\n",
    "for df in dfs:\n",
    "    print(df.columns,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training data has one more feature, `Trip Type`, than the test data.  This is the targer feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change column names to have proper formatting.\n",
    "\n",
    "col=['trip_type','visit_number','weekday','upc','scan_count',\n",
    "     'department_description','fineline_number']\n",
    "train_df.columns=col\n",
    "test_df.columns=col[1:len(col)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect the values of the data to get a rough feel for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_type</th>\n",
       "      <th>visit_number</th>\n",
       "      <th>weekday</th>\n",
       "      <th>upc</th>\n",
       "      <th>scan_count</th>\n",
       "      <th>department_description</th>\n",
       "      <th>fineline_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>6.811315e+10</td>\n",
       "      <td>-1</td>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>6.053882e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>8931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7.410811e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>4504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2.238404e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>3565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2.006614e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>1017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_type  visit_number weekday           upc  scan_count  \\\n",
       "0        999             5  Friday  6.811315e+10          -1   \n",
       "1         30             7  Friday  6.053882e+10           1   \n",
       "2         30             7  Friday  7.410811e+09           1   \n",
       "3         26             8  Friday  2.238404e+09           2   \n",
       "4         26             8  Friday  2.006614e+09           2   \n",
       "\n",
       "  department_description  fineline_number  \n",
       "0     FINANCIAL SERVICES           1000.0  \n",
       "1                  SHOES           8931.0  \n",
       "2          PERSONAL CARE           4504.0  \n",
       "3  PAINT AND ACCESSORIES           3565.0  \n",
       "4  PAINT AND ACCESSORIES           1017.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 647054 entries, 0 to 647053\n",
      "Data columns (total 7 columns):\n",
      "trip_type                 647054 non-null int64\n",
      "visit_number              647054 non-null int64\n",
      "weekday                   647054 non-null object\n",
      "upc                       642925 non-null float64\n",
      "scan_count                647054 non-null int64\n",
      "department_description    645693 non-null object\n",
      "fineline_number           642925 non-null float64\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647054, 7)\n",
      "trip_type                    38\n",
      "visit_number              95674\n",
      "weekday                       7\n",
      "upc                       97714\n",
      "scan_count                   39\n",
      "department_description       68\n",
      "fineline_number            5195\n",
      "dtype: int64 \n",
      "\n",
      "(653646, 6)\n",
      "visit_number              95674\n",
      "weekday                       7\n",
      "upc                       98147\n",
      "scan_count                   49\n",
      "department_description       67\n",
      "fineline_number            5203\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.shape)\n",
    "    print(df.nunique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that each feature is a categorical feature except for `scan_count`.  However, none of them are of this data type yet.  Converting them to this type will reduce the amount of memory required to store and later process the files.\n",
    "\n",
    "However, `visit_number` is not a meaningful category.  That is to say, it is purely a random identification number that is used to group records into a single purchase which which have a single `trip_type` assigned.  Furthermore, because there are so many unique visit numbers, converting them to categorical data types would actually increase memory usage.\n",
    "\n",
    "The same memory issue is true for the `upc` feature.  We will have to be careful to ensure that any future analysis does not assume a meaningful ordering of these numeric values.\n",
    "\n",
    "It should be noted that viewing `department_description` as a category ignores the fact that the values for this variable are word descriptors.  In treating them as categories, we are ignoring this information and eliminating the possibility of text analysis that would attempt to find similar `department_description` values. Naively, I do not think such an analysis would yield strong results anyway.\n",
    "\n",
    "Lastly, as a side note, there are more unique `upc` and `fineline_number` values in the test data than in the training data.  Whatever prediction model is built in the future must be able to make predictions from enough other data for it to be okay for it to see new categories that it was not trained on.  There could potentially be new `department_description` values as well, but I have not checked this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['trip_type']=train_df['trip_type'].astype('category')\n",
    "\n",
    "categoricals=['weekday','department_description','fineline_number']\n",
    "\n",
    "for df in dfs:\n",
    "    for category in categoricals:\n",
    "        df[category]=df[category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one feature that contained numeric information with a meaningful ordering was `scan_count`.  Here, a positive amount indicates what quantity of the product was purchased, whereas a negative amount indicates how much was returned.  Purchasing and returning an item are conceptually different from each other.  For instance, purchasing 1 vs. 3 counts of an item is vastly different from purchasing 1 vs. returning 1, despite both instances having a `scan_count` difference of 2.  For this reason, I have chosen to split this information into two separate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df['purchase_count']=df['scan_count'].clip(lower=0)\n",
    "\n",
    "for df in dfs:\n",
    "    df['return_count']=((-1)*df['scan_count']).clip(lower=0)\n",
    "\n",
    "for df in dfs:\n",
    "    df.drop(columns='scan_count',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "When `train_df.info()` was called earlier, it was observed that there were a few missing values.  Let us return to this point to look at it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_type                    0\n",
      "visit_number                 0\n",
      "weekday                      0\n",
      "upc                       4129\n",
      "department_description    1361\n",
      "fineline_number           4129\n",
      "purchase_count               0\n",
      "return_count                 0\n",
      "dtype: int64 \n",
      "\n",
      "visit_number                 0\n",
      "weekday                      0\n",
      "upc                       3986\n",
      "department_description    1328\n",
      "fineline_number           3986\n",
      "purchase_count               0\n",
      "return_count                 0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(np.sum(pd.isnull(df)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, in both data sets `upc` and `fineline_number` are missing an equal number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4129 \n",
      "\n",
      "3986 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(np.sum((pd.isnull(df.fineline_number))&(pd.isnull(df.upc))),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, `upc` is `NaN` if and only if `fineline_number` is `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1361 \n",
      "\n",
      "1328 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Department being NaN is a subset of the others being NaN\n",
    "for df in dfs:\n",
    "    print(np.sum((pd.isnull(df.department_description))&(pd.isnull(df.upc))),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the records for which `department_description` is `NaN` is a subset of the records for which `upc` and `fineline_number` are `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because so few of the records contain missing values (under 1%), one option would be to drop these records.  However, the fact that there appears to be structure to the missing values and that such values must be dealt with in the test data suggest that this would be a poor decision.  The data cannot be filled with statistical values such as the mean because it is categorical, and it cannot be backfilled because it is not from a time series. One could assign values randomly or use the mode, but there is no evidence yet to indicate that this would be a sensible decision. Instead, the values will be left blank for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the goal is to predict the type of trip each individual customer made.  However, a single trip by a single customer corresponds to multiple records in the dataset because each record is a single item from a single trip by a single customer.  Therefore, we need to group the data by `visit_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_grouped=train_df.groupby('visit_number')\n",
    "test_df_grouped=test_df.groupby('visit_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick sanity check to see that this worked, we will compute whether the number of groups is the same as the number of unique `visit_number` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_grouped.groups.keys())==train_df.nunique()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample of the format of the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_type</th>\n",
       "      <th>visit_number</th>\n",
       "      <th>weekday</th>\n",
       "      <th>upc</th>\n",
       "      <th>department_description</th>\n",
       "      <th>fineline_number</th>\n",
       "      <th>purchase_count</th>\n",
       "      <th>return_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>6.053882e+10</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>8931.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7.410811e+09</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>4504.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_type  visit_number weekday           upc department_description  \\\n",
       "1        30             7  Friday  6.053882e+10                  SHOES   \n",
       "2        30             7  Friday  7.410811e+09          PERSONAL CARE   \n",
       "\n",
       "  fineline_number  purchase_count  return_count  \n",
       "1          8931.0               1             0  \n",
       "2          4504.0               1             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_grouped.get_group(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now in a suitable state for an exploratory statisitcal and graphical analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
