{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 1 Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to present inferential statistics about the Walmart dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Issue On Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular dataset does not lend itself well to a statistical analysis.  Recall that of the 6 original predictive variables, only one of them is numeric: `scan_count`.  Furthermore, this value is limited to being an integer.  It is not even possible to use this value to create a linear regression since the target variable is categorical with 39 different possibilities.  The `visit_number` variable is simply an identifier and also does not provide any insights.  There are no Pearson correlations, p-values, standard deviations, confidence intervals, or any other high-level statistic that can be computed.\n",
    "\n",
    "Instead, we are largely limited to exploring variables individually and simply counting how often they occur.  To this end, I refer the reader back to the data wrangling and storytelling notebooks for this project, which include many such summary descriptions and further discussion of their implications as well as graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chi Square Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, what can be computed is the chi square statistic.  Given a null hypothesis regarding an expected distribution of occurances, the chi square statistic gives a value that measures how far off the experimental distribution is from the expected one.  Namely,\n",
    "\n",
    "$\\chi_c^2=\\sum_{i\\in C_i}\\frac{(O_i-E_i)^2}{E_i}$\n",
    "\n",
    "where $C_i$ is the set of all values for a categorical feature and $c$ is the degrees of freedom.  This can then be used to compute a $p$-value to accept or reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data and previous transformational code as necessary without further comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nick/Desktop/Springboard/Capstone_1/Original_Data\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/Springboard/Capstone_1/Original_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')\n",
    "dfs=[train_df,test_df]\n",
    "\n",
    "col=['trip_type','visit_number','weekday','upc','scan_count',\n",
    "     'department_description','fineline_number']\n",
    "train_df.columns=col\n",
    "test_df.columns=col[1:len(col)]\n",
    "\n",
    "train_df['trip_type']=train_df['trip_type'].astype('category')\n",
    "categoricals=['weekday','department_description','fineline_number']\n",
    "for df in dfs:\n",
    "    for category in categoricals:\n",
    "        df[category]=df[category].astype('category')\n",
    "        \n",
    "for df in dfs:\n",
    "    df['purchase_count']=df['scan_count'].clip(lower=0)\n",
    "for df in dfs:\n",
    "    df['return_count']=((-1)*df['scan_count']).clip(lower=0)\n",
    "for df in dfs:\n",
    "    df.drop(columns='scan_count',axis=1,inplace=True)\n",
    "    \n",
    "train_df_grouped=train_df.groupby('visit_number')\n",
    "test_df_grouped=test_df.groupby('visit_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days of the Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the variables in this data set still do not lend themselves well to this statistic because they take on so many values and it is not clear what a sensible null hypothesis to test would be.  As a demonstration though, we will test the null hypothesis the shoppers equally often on all days of the week with a significance level of $\\alpha=.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of the day of the week for each unique trip\n",
    "day_by_visit={}\n",
    "for visit in train_df.visit_number.unique():\n",
    "    day_by_visit[visit]=train_df_grouped.get_group(visit).iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunday       17124\n",
      "Saturday     16904\n",
      "Friday       15234\n",
      "Monday       12027\n",
      "Wednesday    11612\n",
      "Tuesday      11530\n",
      "Thursday     11243\n",
      "dtype: int64\n",
      "Average:13667.714285714286\n"
     ]
    }
   ],
   "source": [
    "# Count how often each day occurs and compute the average\n",
    "unique_daily_count=pd.Series(list(day_by_visit.values())).value_counts()\n",
    "print(unique_daily_count)\n",
    "print(\"Average:\" + str(np.mean(list(unique_daily_count))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=3090.470911637435, pvalue=0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the chi square statistic and the associated p value\n",
    "from scipy.stats import chisquare\n",
    "chisquare(list(unique_daily_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one would anticipate purely on visual inspection of a distribution for such a large sample size, we have $p\\approx0$.  A calculation on a more precise calculator shows that $p<.00001$.  We reject the null hypothesis that customers shop equally often throughout the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interestingly, let us test the null hypothesis that the number of unique items shoppers buy on a given day is proportional to how often they shop on that day.  This means that the $E_i$ are the proportions obtained in the previous step times the total number of unique items purchased, and the $O_i$ are the total number of unique items actually purchased each day.  The thought is that if more people shop on Saturdays for instance, perhaps Saturday is the day to not just go shopping but to do lots of shopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=5783.841850078856, pvalue=0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(list(train_df['weekday'].value_counts()),         \n",
    "          f_exp=np.array(unique_daily_count)*len(train_df)/sum(list(unique_daily_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was again a horrible null hypothesis that is easily rejected.  Perhaps, on the other hand, lots of people only buy a single item or two on popular days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to bear in mind is that neither of these tends give any indication of what the distributions actually are.  They merely allow us to reject the null hypothesis.  For instance, the first test does not support the claim that people shop on weekend days more than weekdays even though that appears to be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days of the Week and Trip Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be more constructive toward our end goal of predicting trip types to compute chi square statistics from a table of values for trip types against one of the other variables.  There are too many upcs and finelines to compare them to trip types and get a meaningful result.  We will compute the statistic for how many times each trip type occurs on each day of the week.  Specifically, the null hypothesis is that the day of the week and the trip type are independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arrays, where the sub-array entries are how many times there is a unique\n",
    "# visit number for each trip type, and the sub-arrays themselves are days of the week.\n",
    "counts=[]\n",
    "for day in train_df['weekday'].unique():\n",
    "    daycounts=[]\n",
    "    day_df=train_df[train_df['weekday']==day]\n",
    "    for ttype in train_df['trip_type'].unique():\n",
    "        daytype_df=day_df[day_df['trip_type']==ttype]\n",
    "        x=daytype_df.loc[:,'visit_number'].nunique()\n",
    "        daycounts.append(x)\n",
    "    counts.append(daycounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=143674.27020925225, pvalue=0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freedom=(train_df['weekday'].nunique()-1)*(train_df['trip_type'].nunique()-1)\n",
    "chisquare(counts,axis=None,ddof=freedom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the day of the week and the type of trip are not independent of each other.  This is good news for a future machine learning model, as it means that the day of the week is a useful predictive feature.  However, we are still limited in our interpretability of the result, as it does not give any indication of what the actual distribution is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
